{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa5b71-a63d-4303-931d-ba37775bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17965b-a274-430a-a2fd-55b5098763c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dask.array as da \n",
    "import pandas as pd\n",
    "#import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46276d8-a3a0-4b96-ab48-46f0e8edca8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e797f4-1d8a-43a5-b588-88372a16d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"/store/ronnieleeper/activeProjects/soilQC/SoilMoistureQC/data/acclima_soil_water-full_wo_duplicates-20221130.csv\",dtype={'PRECIPITATION': 'float64'})\n",
    "#new dataset\n",
    "df = pd.read_csv(\"/store/ronnieleeper/activeProjects/soilQC/SoilMoistureQC/data/acclima_soil_water-full_with_tipping_bucket_and_wetness-20230113.csv\",dtype={'PRECIPITATION': 'float64'})# Old data - /store/ronnieleeper/activeProjects/soilQC/SoilMoistureQC/data/acclima_soil_water-full_wo_duplicates-20221130.csv\n",
    "# Add column to easily detect normal / flagged data\n",
    "df['FLAG'] = df.NOPRCPRESPONSE + df.FROZENRECOVERY+ df.NOISE + df.FAILURE + df.STATIC+df.ERRATIC+ df.DIURNALNOISE+df.TOOHIGH+df.SCALING + df.ZERO+df.SPIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e474ff3-b0bf-41e6-8ded-0728deb20a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UTC_START'] = pd.to_datetime(df['UTC_START'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fafe18-275f-47c6-9c2f-48da63c5a0f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get number of unique sensors for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9b54f-d1d2-4839-9dae-5255e69dc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stations and the number of sensors they have\n",
    "station_sensor_counts = df.groupby('STATION_ID').VARIABLE.nunique()\n",
    "station_sensor_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f36d8e-2241-481b-aea5-8de4afdf94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_sensor_dist = df.groupby('STATION_ID').VARIABLE.value_counts()\n",
    "station_sensor_dist= pd.DataFrame(station_sensor_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f10bb-49de-4b5f-991e-858df32ce7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_with_15_vars = list(station_sensor_counts[station_sensor_counts == 15].index)\n",
    "station_with_14_vars = list(station_sensor_counts[station_sensor_counts == 14].index)\n",
    "station_with_13_vars = list(station_sensor_counts[station_sensor_counts == 13].index)\n",
    "station_with_more_than_13_vars = list(station_sensor_counts[station_sensor_counts >= 13].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41922edb-8433-40b9-9fd0-da09c5a287f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just sample code for plotting available sensor readings over time\n",
    "fig, ax = plt.subplots(1,1)\n",
    "sns.scatterplot(data=df[(df['STATION_ID']==1012)],x='UTC_START',y='VARIABLE', ax=ax)\n",
    "ax.set_title(\"Sensor data for station 1012\")\n",
    "ax.set_xlabel(\"Time stamps (UTC_START)\")\n",
    "ax.set_ylabel(\"Sensors (VARIABLE)- 13 present\")\n",
    "#ax.set_xlim(1,10)\n",
    "#plt.xlim(x_limit)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('./data_plots/13sensors/station_1012_sensors.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e6ffa-b098-4df4-b6bd-62d23e2d4f1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Common Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0cea25-233f-469c-8923-c6db57d9df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert precipitation to Boolean - TEMPORARY MEASURE, CHANGE ONCE NEW DATA OBTAINED\n",
    "df['PRECIPITATION'] = df['PRECIPITATION'].fillna(value= 0.0)\n",
    "#df.PRECIPITATION = df.where(df.PRECIPITATION.compute() == 0, 1) # TEMPORARY MEASURE, CHANGE ONCE NEW DATA OBTAINED\n",
    "def make_boolean(x):\n",
    "    if x <500.0:\n",
    "        return 1\n",
    "    elif x > 500.0:\n",
    "        return 0\n",
    "#df['PRECIPITATION'] = df['PRECIPITATION'].apply(lambda x: make_boolean(x))\n",
    "df['PRECIPITATION'] = df['WETNESS_1'].apply(lambda x: make_boolean(x))\n",
    "print(\"Null values in precipitation\",df['PRECIPITATION'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3174f-405a-4080-b86e-1e1b310ab391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying dataset by merging output classes into noise, spike or no flag\n",
    "df_modified = df.drop(['NOPRCPRESPONSE','ZERO','TOOHIGH','ERRATIC','FAILURE','SCALING','FLAG','TIPPING_BUCKET','WETNESS_2'],axis=1)\n",
    "#0 -> non-flagged/ normal, 1-> SPIKE, 2 -> Noise\n",
    "def update_flag(row):\n",
    "    if row['SPIKE'] == 1:\n",
    "        return 1\n",
    "    elif row['NOISE'] == 1 or row['DIURNALNOISE'] == 1 or row['FROZENRECOVERY']==1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "df_modified['FLAG'] = df_modified.apply(lambda x: update_flag(x), axis=1)\n",
    "df_modified.drop(['FROZENRECOVERY','DIURNALNOISE','NOISE','SPIKE'],axis=1,inplace=True)\n",
    "df_modified.drop('WBAN',axis=1,inplace=True)\n",
    "df_modified.drop('WETNESS_1',axis=1,inplace=True)\n",
    "df_modified.drop('STATIC',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0ee95-1115-4479-9154-7863b9ec72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers \n",
    "df_modified = df_modified[(df_modified['VOLUMETRIC'] > 0.0) & (df['VOLUMETRIC'] < 0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089e808-f243-400b-afb8-63d20da7b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data per station \n",
    "TODO: HAVE TO NORMALOSE TRAIN AND TEST SEPERATELY. IT IS DONE AT THE START OF EACH APPROACH\n",
    "#df_modified[['TEMPERATURE','VOLUMETRIC']] = df_modified[['TEMPERATURE','VOLUMETRIC','STATION_ID','VARIABLE']].groupby(['STATION_ID', 'VARIABLE']).transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e2fe96-c04e-41b1-8154-fcef8a35026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_depth(row):\n",
    "    return int(row[-3:])\n",
    "\n",
    "df_modified['VARIABLE'] = df_modified['VARIABLE'].apply(extract_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c9caf-0bb6-4030-9230-15b5f961378c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LazyPredict : to get a sense of classifier performance. Run as script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1c2a9-b14d-4316-878c-99aa209183f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_modified_sampled = df_modified.sample(n=100)\n",
    "X = df_modified_sampled.drop(['FLAG'],axis=1)\n",
    "y = df_modified_sampled['FLAG']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state =42)\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)\n",
    "\n",
    "models.to_csv('./data_plots/param_opt_models_sample_tab.csv',sep='\\t')\n",
    "predictions.to_csv('./data_plots/param_opt_predictions_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7157624b-a290-4f9d-86a3-a6f9a718db70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_modified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6179/357958299.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_modified_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_modified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_modified_sampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FLAG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_modified_sampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FLAG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_modified' is not defined"
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_modified_sampled = df_modified.sample(n=100)\n",
    "X = df_modified_sampled.drop(['FLAG'],axis=1)\n",
    "y = df_modified_sampled['FLAG']\n",
    "\n",
    "x_subset = X#.sample(n=1000)  takes too long to run in notebook, so sample just to check. run on full data as script\n",
    "y_subset = y#.sample(n=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_subset,y_subset,test_size=.2,random_state =42)\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e703ad-1390-4c4e-9390-bb1d30f5710d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Approach 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4807a-0990-4575-a404-bc7eb7be07ee",
   "metadata": {},
   "source": [
    "use the data as is to learn “rules” specific to stations at various sensor depth. The input columns now are:   {station_ID, sensor_name (depth), volumetric, temp, precip_binary, flag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78f056-4d25-43d2-ba3d-0179a1742d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9374e05-9ae1-4db8-8309-f805772b8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZING TRAIN AND TEST DATA SEPERATELY ON STATION AND VARIABLE\n",
    "from sklearn.preprocessing import Normalizer\n",
    "df_modified.drop('UTC_START',axis=1,inplace=True)\n",
    "\n",
    "#data1 = df_modified[['VOLUMETRIC','TEMPERATURE','STATION_ID','VARIABLE']].groupby(['STATION_ID', 'VARIABLE']).transform(lambda x: (x - x.mean()) / x.std())\n",
    "temp = {}\n",
    "vol = {}\n",
    "\n",
    "for g in x_train[['VOLUMETRIC','TEMPERATURE','STATION_ID','VARIABLE']].groupby(['STATION_ID', 'VARIABLE']):\n",
    "    temp[g[0]] = (g[1].TEMPERATURE.mean(), g[1].TEMPERATURE.std())\n",
    "    vol[g[0]] = (g[1].VOLUMETRIC.mean(), g[1].VOLUMETRIC.std())\n",
    "    x_train.loc[g[1].index,'TEMPERATURE'] = (x_train.loc[g[1].index,'TEMPERATURE'] - g[1].TEMPERATURE.mean())/g[1].TEMPERATURE.std()\n",
    "    x_train.loc[g[1].index,'VOLUMETRIC'] = (x_train.loc[g[1].index,'VOLUMETRIC'] - g[1].VOLUMETRIC.mean())/g[1].VOLUMETRIC.std()\n",
    "\n",
    "for g in x_test[['VOLUMETRIC','TEMPERATURE','STATION_ID','VARIABLE']].groupby(['STATION_ID', 'VARIABLE']):\n",
    "    x_test.loc[g[1].index,'TEMPERATURE'] = (x_test.loc[g[1].index,'TEMPERATURE'] - temp[g[0]][0])/temp[g[0]][1]\n",
    "    x_test.loc[g[1].index,'VOLUMETRIC'] = (x_test.loc[g[1].index,'VOLUMETRIC'] - temp[g[0]][0])/temp[g[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8199233-645e-4023-a684-4a5df59761f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=20,shuffle=True,random_state=42)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "        dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"In split: \",i)\n",
    "        #models.append(xgb_model)\n",
    "        y_pred = xgb_model.predict(X_test)\n",
    "        y_pred_dummy = dummy_clf.predict(X_test)\n",
    "        labels = xgb_model.classes_\n",
    "        conf_df = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=labels, index=labels)\n",
    "        conf_df.index.name = 'True labels'\n",
    "        print(\"----Confusion matrix:\")\n",
    "        print(conf_df)\n",
    "\n",
    "        f_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        f_none = f1_score(y_test, y_pred, average=None)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f_macro_dummy = f1_score(y_test, y_pred_dummy, average='macro')\n",
    "        f_none_dummy = f1_score(y_test, y_pred_dummy, average=None)\n",
    "        acc_dummy = accuracy_score(y_test, y_pred_dummy)\n",
    "        print(\"----F1 score macro (xgboost): \" , f_macro)\n",
    "        print(\"----F1 score none (xgboost): \" , f_none)\n",
    "        print(\"----Accuracy (xgboost): \", acc)\n",
    "        print(\"----F1 score macro (dummy): \" , f_macro_dummy)\n",
    "        print(\"----F1 score none (dummy): \" , f_none_dummy)\n",
    "        print(\"----Accuracy (dummy): \", acc_dummy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a1391a-a8bd-473a-bd24-3378e508ee34",
   "metadata": {},
   "source": [
    "### sample weights for unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a644aef-a3c6-4a49-baa7-8b76346078a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(x_train, y_train,sample_weight=classes_weights)\n",
    "\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "#y_pred_dummy = dummy_clf.predict(X_test)\n",
    "    \n",
    "f_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f_none = f1_score(y_test, y_pred, average=None)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"----F1 score macro (xgboost): \" , f_macro)\n",
    "print(\"----F1 score none (xgboost): \" , f_none)\n",
    "print(\"----Accuracy (xgboost): \", acc)\n",
    "                              \n",
    "labels = xgb_model.classes_\n",
    "conf_df = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=labels, index=labels)\n",
    "conf_df.index.name = 'True labels'\n",
    "print(conf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee4286-4049-4936-a2c3-feafa5a6a659",
   "metadata": {},
   "source": [
    "### parameter optimization using RandomsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967ce14-16e8-4bd1-9005-54d4146723e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detailed model as script\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0,stratify= y)\n",
    "parameters = {\n",
    "      'learning_rate': [0.5,0.6, 0.65, 0.7, 0.8],\n",
    "      'max_depth': [ 25,30,40,55],\n",
    "      'n_estimators': [300,500,750,1250, 1500, 1750],\n",
    "      \"reg_alpha\"   : [0.3,0.4,0.5,0.6],\n",
    "      \"reg_lambda\"  : [2],\n",
    "      \"gamma\"       : [0.1,0.5,1]}\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "grid_obj_xgb = RandomizedSearchCV(xgb_model,parameters, cv=5,n_iter=40,verbose=3,n_jobs=30)\n",
    "classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "search = grid_obj_xgb.fit(x_train, y_train,sample_weight=classes_weights,verbose=4)\n",
    "print(\"best params: \",search.best_params_)\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "f_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f_none = f1_score(y_test, y_pred, average=None)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"----F1 score macro (xgboost): \" , f_macro)\n",
    "print(\"----F1 score none (xgboost): \" , f_none)\n",
    "print(\"----Accuracy (xgboost): \", acc)\n",
    "                              \n",
    "labels = xgb_model.classes_\n",
    "conf_df = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=labels, index=labels)\n",
    "conf_df.index.name = 'True labels'\n",
    "print(conf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4187ed0-cec2-4557-ad53-1db31f217800",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d56686-87ef-4409-9fb1-c2b6a18f8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only stations with 13 or more sensor readings\n",
    "df_modified = df_modified[df_modified.STATION_ID.isin(station_with_more_than_13_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d41d6-d696-413a-baf7-e641d1a3aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data, so for a given timestamp and station there is 1 row with values for all sensor \n",
    "df_pivot = df_modified.pivot(index=['STATION_ID','UTC_START'],columns='VARIABLE',values=['TEMPERATURE','VOLUMETRIC','PRECIPITATION','FLAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad7cdd-ab27-452f-b1a4-9080a2801fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert multiple flag columns to only 1 column\n",
    "df_pivot['FLAG_upd'] = df_pivot.FLAG.max(axis=1)\n",
    "\n",
    "df_pivot['FLAG_upd'] = df_pivot['FLAG_upd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c3202-3410-4b4f-9b36-ca9d6acb3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.drop([('FLAG', 'sw1005'),\n",
    "            (         'FLAG', 'sw1010'),\n",
    "            (         'FLAG', 'sw1020'),\n",
    "            (         'FLAG', 'sw1050'),\n",
    "            (         'FLAG', 'sw1100'),\n",
    "            (         'FLAG', 'sw2005'),\n",
    "            (         'FLAG', 'sw2010'),\n",
    "            (         'FLAG', 'sw2020'),\n",
    "            (         'FLAG', 'sw2050'),\n",
    "            (         'FLAG', 'sw2100'),\n",
    "            (         'FLAG', 'sw3005'),\n",
    "            (         'FLAG', 'sw3010'),\n",
    "            (         'FLAG', 'sw3020'),\n",
    "            (         'FLAG', 'sw3050'),\n",
    "            (         'FLAG', 'sw3100')],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8700e4-ad74-4122-b379-15696624c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make station ID as a column\n",
    "df_pivot.reset_index('STATION_ID', inplace=True)\n",
    "df_pivot.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580fa51-52fe-4c29-b60d-7a0cb7909597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_temp(row):\n",
    "    #return max(row[('TEMPERATURE','sw1010')],row[('TEMPERATURE','sw1005')],row[('TEMPERATURE','sw1020')],row[('TEMPERATURE','sw1050')],row[('TEMPERATURE','sw1100')],row[('TEMPERATURE','sw2010')],row[('TEMPERATURE','sw2005')],row[('TEMPERATURE','sw2020')],row[('TEMPERATURE','sw2050')],row[('TEMPERATURE','sw2100')],row[('TEMPERATURE','sw3010')],row[('TEMPERATURE','sw3005')],row[('TEMPERATURE','sw3020')],row[('TEMPERATURE','sw3050')],row[('TEMPERATURE','sw3100')])\n",
    "    idx = row['TEMPERATURE'].first_valid_index()\n",
    "    return row[('TEMPERATURE',idx)]\n",
    "def consolidate_precip(row):\n",
    "    idx = row['PRECIPITATION'].first_valid_index()\n",
    "    return row[('PRECIPITATION',idx)]\n",
    "#    return max(row[('PRECIPITATION','sw1010')],row[('PRECIPITATION','sw1005')],row[('PRECIPITATION','sw1020')],row[('PRECIPITATION','sw1050')],row[('PRECIPITATION','sw1100')],row[('PRECIPITATION','sw2010')],row[('PRECIPITATION','sw2005')],row[('PRECIPITATION','sw2020')],row[('PRECIPITATION','sw2050')],row[('PRECIPITATION','sw2100')],row[('PRECIPITATION','sw3010')],row[('PRECIPITATION','sw3005')],row[('PRECIPITATION','sw3020')],row[('PRECIPITATION','sw3050')],row[('PRECIPITATION','sw3100')])\n",
    "\n",
    "df_pivot['TEMPERATURE_1'] = df_pivot.apply(lambda x: consolidate_temp(x), axis=1)\n",
    "df_pivot['PRECIPITATION_1'] = df_pivot.apply(lambda x: consolidate_precip(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7afc5e-ab36-44dc-a09c-ea6a19672b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_missing_sensor(row):\n",
    "    row[('VOLUMETRIC','sw1010')] = max(row[('VOLUMETRIC','sw1010')] ,row[('VOLUMETRIC','sw2010')],row[('VOLUMETRIC','sw3010')])\n",
    "    row[('VOLUMETRIC','sw1005')] = max(row[('VOLUMETRIC','sw1005')] ,row[('VOLUMETRIC','sw2005')],row[('VOLUMETRIC','sw3050')])\n",
    "    row[('VOLUMETRIC','sw1020')] = max(row[('VOLUMETRIC','sw1020')] ,row[('VOLUMETRIC','sw2020')],row[('VOLUMETRIC','sw3020')])\n",
    "    row[('VOLUMETRIC','sw1050')] = max(row[('VOLUMETRIC','sw1050')] ,row[('VOLUMETRIC','sw2050')],row[('VOLUMETRIC','sw3050')])\n",
    "    row[('VOLUMETRIC','sw1100')] = max(row[('VOLUMETRIC','sw1100')] ,row[('VOLUMETRIC','sw2100')],row[('VOLUMETRIC','sw3100')])\n",
    "    \n",
    "    # For temaperature\n",
    "    #row[('TEMPERATURE','sw1010')] = max(row[('TEMPERATURE','sw1010')] ,row[('TEMPERATURE','sw2010')],row[('TEMPERATURE','sw3010')])\n",
    "    #row[('TEMPERATURE','sw1005')] = max(row[('TEMPERATURE','sw1005')] ,row[('TEMPERATURE','sw2005')],row[('TEMPERATURE','sw3050')])\n",
    "    #row[('TEMPERATURE','sw1020')] = max(row[('TEMPERATURE','sw1020')] ,row[('TEMPERATURE','sw2020')],row[('TEMPERATURE','sw3020')])\n",
    "    #row[('TEMPERATURE','sw1050')] = max(row[('TEMPERATURE','sw1050')] ,row[('TEMPERATURE','sw2050')],row[('TEMPERATURE','sw3050')])\n",
    "    #row[('TEMPERATURE','sw1100')] = max(row[('TEMPERATURE','sw1100')] ,row[('TEMPERATURE','sw2100')],row[('TEMPERATURE','sw3100')])\n",
    "    \n",
    "    #row[('PRECIPITATION','sw1010')] = max(row[('PRECIPITATION','sw1010')] ,row[('PRECIPITATION','sw2010')],row[('PRECIPITATION','sw3010')])\n",
    "    #row[('PRECIPITATION','sw1005')] = max(row[('PRECIPITATION','sw1005')] ,row[('PRECIPITATION','sw2005')],row[('PRECIPITATION','sw3050')])\n",
    "    #row[('PRECIPITATION','sw1020')] = max(row[('PRECIPITATION','sw1020')] ,row[('PRECIPITATION','sw2020')],row[('PRECIPITATION','sw3020')])\n",
    "    #row[('PRECIPITATION','sw1050')] = max(row[('PRECIPITATION','sw1050')] ,row[('PRECIPITATION','sw2050')],row[('PRECIPITATION','sw3050')])\n",
    "    #row[('PRECIPITATION','sw1100')] = max(row[('PRECIPITATION','sw1100')] ,row[('PRECIPITATION','sw2100')],row[('PRECIPITATION','sw3100')])\n",
    "    \n",
    "    return row\n",
    "df_pivot = df_pivot.apply(lambda x: update_missing_sensor(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c04a8f-055c-418b-bcd9-079e01b49494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.drop([\n",
    "            (         'TEMPERATURE', 'sw1005'),\n",
    "            (         'TEMPERATURE', 'sw1010'),\n",
    "            (         'TEMPERATURE', 'sw1020'),\n",
    "            (         'TEMPERATURE', 'sw1050'),\n",
    "            (         'TEMPERATURE', 'sw1100'),\n",
    "            (         'TEMPERATURE', 'sw2005'),\n",
    "            (         'TEMPERATURE', 'sw2010'),\n",
    "            (         'TEMPERATURE', 'sw2020'),\n",
    "            (         'TEMPERATURE', 'sw2050'),\n",
    "            (         'TEMPERATURE', 'sw2100'),\n",
    "            (         'TEMPERATURE', 'sw3005'),\n",
    "            (         'TEMPERATURE', 'sw3010'),\n",
    "            (         'TEMPERATURE', 'sw3020'),\n",
    "            (         'TEMPERATURE', 'sw3050'),\n",
    "            (         'TEMPERATURE', 'sw3100')],axis=1,inplace=True)\n",
    "\n",
    "df_pivot.drop([\n",
    "            (         'VOLUMETRIC', 'sw2005'),\n",
    "            (         'VOLUMETRIC', 'sw2010'),\n",
    "            (         'VOLUMETRIC', 'sw2020'),\n",
    "            (         'VOLUMETRIC', 'sw2050'),\n",
    "            (         'VOLUMETRIC', 'sw2100'),\n",
    "            (         'VOLUMETRIC', 'sw3005'),\n",
    "            (         'VOLUMETRIC', 'sw3010'),\n",
    "            (         'VOLUMETRIC', 'sw3020'),\n",
    "            (         'VOLUMETRIC', 'sw3050'),\n",
    "            (         'VOLUMETRIC', 'sw3100')],axis=1,inplace=True)\n",
    "\n",
    "df_pivot.drop([\n",
    "            (         'PRECIPITATION', 'sw1005'),\n",
    "            (         'PRECIPITATION', 'sw1010'),\n",
    "            (         'PRECIPITATION', 'sw1020'),\n",
    "            (         'PRECIPITATION', 'sw1050'),\n",
    "            (         'PRECIPITATION', 'sw1100'),\n",
    "            (         'PRECIPITATION', 'sw2005'),\n",
    "            (         'PRECIPITATION', 'sw2010'),\n",
    "            (         'PRECIPITATION', 'sw2020'),\n",
    "            (         'PRECIPITATION', 'sw2050'),\n",
    "            (         'PRECIPITATION', 'sw2100'),\n",
    "            (         'PRECIPITATION', 'sw3005'),\n",
    "            (         'PRECIPITATION', 'sw3010'),\n",
    "            (         'PRECIPITATION', 'sw3020'),\n",
    "            (         'PRECIPITATION', 'sw3050'),\n",
    "            (         'PRECIPITATION', 'sw3100')],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d0878-22ad-4972-bf2c-d5c06fed3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.dropna(axis=0,inplace=True)\n",
    "df_pivot.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd75cc-cc25-453b-8c5b-5b85325b9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pivot.drop([(    'UTC_START',       ''),(     'FLAG_upd',       '')],axis=1)\n",
    "y = df_pivot['FLAG_upd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fbe31d-ba12-42c6-8c79-9f4c5b338a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0,stratify= df_pivot['FLAG_upd'])  \n",
    "y_pred = xgb_model.predict(x_test)\n",
    "\n",
    "labels = xgb_model.classes_\n",
    "conf_df = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=labels, index=labels)\n",
    "conf_df.index.name = 'True labels'\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48544b7-e163-4ea1-93f5-d359e67c1e8d",
   "metadata": {},
   "source": [
    "### K fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18227c-4865-4c9b-9b14-ef20e5475300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "accuracies =[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=11)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    #train = df.loc[train_index,:]\n",
    "    #test = df.loc[test_index,:]\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f534c-89ac-4e82-b8a2-bcfc3d285cfe",
   "metadata": {},
   "source": [
    "### Group K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de657cf6-e2e8-4c31-8874-db929cde6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "accuracies =[]\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "X = df_pivot.drop([(    'UTC_START',       ''),(     'FLAG_upd',       '')],axis=1)\n",
    "y = df_pivot['FLAG_upd']\n",
    "skf = GroupKFold(n_splits=len(df_pivot.groupby('STATION_ID')))\n",
    "groups = df_pivot['STATION_ID'].values\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y,groups)):\n",
    "    #train = df.loc[train_index,:]\n",
    "    #test = df.loc[test_index,:]\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16e06d-658d-49b1-ac0d-815bb6b4f9c8",
   "metadata": {},
   "source": [
    "### Stratified group K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f507d46-9d41-450b-af7e-7862cc2fce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "accuracies =[]\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "X = df_pivot.drop([(    'UTC_START',       ''),(     'FLAG_upd',       '')],axis=1)\n",
    "y = df_pivot['FLAG_upd']\n",
    "skf = StratifiedGroupKFold(n_splits=len(df_pivot.groupby('STATION_ID')))\n",
    "groups = df_pivot['STATION_ID'].values\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y,groups)):\n",
    "    #train = df.loc[train_index,:]\n",
    "    #test = df.loc[test_index,:]\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7c457-13db-4a41-b99a-72cad48b2d4d",
   "metadata": {},
   "source": [
    "## Unsupervised learning - Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8522e1-7684-48d7-a043-7015ab460a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc8075-8dcc-463b-946b-253d82edf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample only noise and normal data\n",
    "df_modified = df_modified[(df_modified['FLAG'] == 2) | (df_modified['FLAG'] == 0)]\n",
    "\n",
    "X = df_modified.drop(['FLAG','UTC_START'],axis=1)\n",
    "y = df_modified['FLAG']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0,stratify= y)   \n",
    "# To find contamination for IF\n",
    "len(df_modified[df_modified['FLAG'] == 2])/len(df_modified['FLAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a81dd-25de-43a4-bd90-f4f9fc1ece06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified2 = X.drop('PRECIPITATION', axis=1)\n",
    "\n",
    "random_state = np.random.RandomState(42)\n",
    "model2=IsolationForest(n_estimators=300,max_samples='auto',contamination=float(0.04),random_state=random_state)\n",
    "model2.fit(X_modified2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851cfca-60ee-4b23-8d1c-59cdb9f52eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_modified2['anomaly_scores'] = model2.predict(X_modified2)\n",
    "#X_modified2['scores'] = model2.decision_function(X_modified2.drop('anomaly_scores',axis=1))\n",
    "X_modified2['TRUE_VAL'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52cd494-b99b-4247-b2d0-58dab017ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix_vals(row):\n",
    "    if row['anomaly_scores'] == -1 and row['TRUE_VAL'] == 2:\n",
    "        return 0 #TP\n",
    "    elif row['anomaly_scores'] == -1 and row['TRUE_VAL'] == 0:\n",
    "        return 1 #FP\n",
    "    elif row['anomaly_scores'] == 1 and row['TRUE_VAL'] == 0:\n",
    "        return 2 #TN\n",
    "    else:\n",
    "        return 3 #FN\n",
    "X_modified2['conv_matrix_value'] = X_modified2.apply(lambda x: get_conf_matrix_vals(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6028e9-6b8d-4267-a5bc-b134471c5715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
